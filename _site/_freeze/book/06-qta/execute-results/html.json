{
  "hash": "4545af256183bd76fbf087c1dc314960",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"§6 Quantitative Text Analysis Basics 📊\"\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-link: true\n    highlight-style: github\n    include-in-header:\n      text: |\n        <script src=\"quiz.js\"></script>\n        <script src=\"content-switch.js\"></script>\nfilters: \n - collapse-callout.lua\nexecute:\n  freeze: auto\n---\n\n\n\n\n\n\n\n\n\n\nWelcome to the world of quantitative text analysis! In this chapter, we'll explore the fundamental concepts and techniques used to prepare text data for analysis. We'll use a collection of classic novels as our dataset to demonstrate these concepts.\n\n::: {.callout-note}\n## Learning Objectives\n- 📖 Understand the basics of text analysis and its applications in Digital Humanities\n- 🧹 Learn essential text preprocessing techniques\n- 🔤 Explore basic text analysis concepts like tokenization and word frequency\n- 📊 Visualize text data using simple techniques like word clouds\n:::\n\n# What is Quantitative Text Analysis? 🤔\n\nQuantitative text analysis (QTA) is a method of analyzing large volumes of text data using computational techniques. It allows researchers to extract meaningful patterns, themes, and insights from textual data that would be difficult or impossible to analyze manually.\n\n## QTA in Digital Humanities\n\nIn Digital Humanities, QTA offers powerful tools for exploring large text corpora:\n\n1. **Scale**: Analyze vast collections of texts, revealing patterns across time periods, genres, or authors.\n\n2. **Distant Reading**: Observe broader patterns in literature and cultural production.\n\n3. **Hypothesis Testing**: Empirically test literary and cultural theories across large datasets.\n\n4. **Discovery**: Reveal unexpected patterns or connections, sparking new research questions.\n\n5. **Interdisciplinary**: Combine methods from linguistics, computer science, and statistics with humanistic inquiry.\n\n6. **Visualization**: Present textual data in new, visually interpretable ways.\n\nQTA complements traditional close reading, offering Digital Humanities scholars new perspectives on cultural, historical, and literary phenomena.\n\n\n# Our Dataset: Pride and Prejudice 📚\n\nFor this chapter, we'll use Jane Austen's \"Pride and Prejudice\" to demonstrate text analysis techniques. We'll access this novel using the `janeaustenr` package.\n\n## Install Package Manager `pacman`\n\nBefore we begin our text analysis, let's introduce a helpful tool for managing R packages: `pacman`. The `pacman` package is a convenient package management tool for R that simplifies the process of loading and installing multiple packages.\n\nKey features of `pacman`:\n\n1. It combines the functionality of `install.packages()` and `library()` into a single function `p_load()`.\n2. It automatically installs packages if they're not already installed.\n3. It can load multiple packages with a single line of code.\n\nLet's install and load `pacman`:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(\"pacman\")) install.packages(\"pacman\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: pacman\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(pacman)\n```\n:::\n\n\n\n\n\n\n\n\n\n\nNow we can use `p_load()` to efficiently load (and install if necessary) the packages we'll need for our text analysis:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_load(janeaustenr, tidyverse)\n```\n:::\n\n\n\n\n\n\n\n\n\n\nThis single line will ensure all the packages we need are installed and loaded, streamlining our setup process.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_and_prejudice <- austen_books() %>%\n  filter(book == \"Pride & Prejudice\")\n\npride_and_prejudice\n```\n:::\n\n\n\n\n\n\n\n\n\n\nAlternatively, if you have trouble downloading the data with R, you can download it here:For this chapter, we'll use Jane Austen's \"Pride and Prejudice\" to demonstrate text analysis techniques. You can download the dataset we'll be using here:\n\n[Download Pride and Prejudice dataset](data/pride_and_prejudice.csv)\n\nYou can load the data with the following command:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_and_prejudice <- read_csv(\"data/pride_and_prejudice.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 13030 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): text, book\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npride_and_prejudice\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13,030 × 2\n   text                                                                    book \n   <chr>                                                                   <chr>\n 1 PRIDE AND PREJUDICE                                                     Prid…\n 2 <NA>                                                                    Prid…\n 3 By Jane Austen                                                          Prid…\n 4 <NA>                                                                    Prid…\n 5 <NA>                                                                    Prid…\n 6 <NA>                                                                    Prid…\n 7 Chapter 1                                                               Prid…\n 8 <NA>                                                                    Prid…\n 9 <NA>                                                                    Prid…\n10 It is a truth universally acknowledged, that a single man in possession Prid…\n# ℹ 13,020 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nThis gives us the full text of \"Pride and Prejudice\" in a tidy format, with one line per row.\n\n# Text Preprocessing Techniques 🧹\n\nBefore we dive into the technical aspects of preparing text for analysis, let's take a moment to think about how we interact with text in our everyday lives.\n\n::: {.callout-tip}\n## Reflection\n\nImagine you're reading a book and taking notes for a literature class. You might underline important passages, write summaries in the margins, or create a list of key themes.\n\n- What kinds of information do you focus on?\n- What do you tend to ignore or skim over?\n- How might your note-taking process change if you want to read hundreds of books instead of just one?\n\nTake a few minutes to jot down your thoughts or discuss with a classmate. These reflections can help us understand the choices we make when preparing texts for computational analysis.\n:::\n\n<div id=\"reflection-insights\" style=\"display: none;\">\n::: {.callout-note}\n## Reflection Insights\n\nWhen we read and take notes, we often:\n\n1. Focus on: main ideas, character development, plot points, themes, and notable quotes.\n2. Skim over: common words, detailed descriptions, or repetitive information.\n3. For analyzing many books: we might create more structured notes, use consistent categories across books, and focus on comparing and contrasting elements.\n\nThese human reading strategies have parallels in computational text analysis:\n\n- Focusing on key information → Extracting features or topics\n- Skimming common words → Removing stopwords\n- Structured note-taking → Creating consistent data formats\n\nAs we explore text preprocessing techniques, we'll see how these human reading strategies are adapted for computational analysis.\n:::\n</div>\n\n<script>\ncreateToggleSection('reflection-insights-button', 'reflection-insights', 'Show Insights');\n</script>\n\nNow, let's explore how computers \"read\" and prepare texts for analysis. This process, known as text preprocessing, is a crucial first step in quantitative text analysis.\n\n::: {.callout-note}\n## Understanding Text Preprocessing\n\nText preprocessing is the crucial first step in quantitative text analysis. It involves cleaning and standardizing raw text data to make it suitable for computational analysis.\n\n**Why is it important?**\n- Improves data quality and consistency\n- Reduces noise and irrelevant information\n- Enhances the accuracy of subsequent analyses\n- Makes text data more manageable for computational processing\n\n**Fundamental considerations:**\n1. **Purpose**: The preprocessing steps you choose should align with your research questions and analysis goals.\n2. **Language**: Different languages may require specific preprocessing techniques.\n3. **Domain**: The nature of your texts (e.g., literary, social media, historical) may influence preprocessing decisions.\n4. **Information preservation**: Be cautious not to remove potentially important information during preprocessing.\n5. **Reproducibility**: Document your preprocessing steps to ensure your analysis can be replicated.\n\nRemember, there's no one-size-fits-all approach to preprocessing. The techniques you apply should be carefully considered based on your specific research context.\n:::\n\n## 1. Lowercasing\n\n[Explanation and example of lowercasing]\n\n## 2. Removing Punctuation\n\n[Explanation and example of punctuation removal]\n\n## 3. Removing Numbers\n\n[Explanation and example of number removal]\n\n## 4. Removing Whitespace\n\n[Explanation and example of whitespace removal]\n\n## 5. Removing Special Characters\n\n[Explanation and example of special character removal]\n\n# Basic Text Analysis Concepts 🔤\n\n## 1. Tokenization\n\n[Explanation of tokenization with word and sentence examples]\n\n## 2. Stopword Removal\n\n[Explanation of stopwords and their removal]\n\n## 3. Word Frequency Analysis\n\n[Introduction to word frequency analysis with examples]\n\n# Visualizing Text Data 📊\n\n## 1. Word Clouds\n\n[Introduction to word clouds with an example using our novel dataset]\n\n## 2. Bar Charts of Word Frequency\n\n[Creating a simple bar chart of most frequent words]\n\n# Hands-On Coding 💻\n\n[A series of exercises for students to practice the concepts learned, similar to the slot machine exercises in the Tidyverse chapter]\n\n# Learning Check 🏁\n\n[A quiz to test understanding of the key concepts covered in the chapter]\n\n::: {.callout-note}\n## Key Takeaways\n[Summary of the main points covered in the chapter]\n:::\n\n::: {.topic-flow}\n[Visual representation of the chapter's flow, similar to the Tidyverse chapter]\n:::\n\n[Include the floating traffic and dashboard iframes as in the Tidyverse chapter]\n\n# Conclusion\n\n[Summary of key takeaways from the chapter]\n\n::: {.callout-note}\n## Key Takeaways\n- The importance of text preprocessing in quantitative text analysis\n- Techniques for analyzing word frequencies and relationships\n- Basic approaches to authorship attribution\n- The process of extracting and interpreting stylometric features\n- Limitations and ethical considerations in text analysis\n:::\n\n::: {.topic-flow}\n::: {.topic-box .highlight-blue}\nText Preprocessing\n:::\n::: {.topic-box .highlight-green}\nWord Frequency Analysis\n:::\n::: {.topic-box .highlight-yellow}\nStylometric Features\n:::\n::: {.topic-box .highlight-pink}\nAuthor Attribution\n:::\n:::\n\n<iframe src=\"float_traffic.html\" width=\"200px\" height=\"200px\" style=\"border:none; position: fixed; bottom: 10px; right: 10px; z-index: 9999;\" scrolling=\"no\"></iframe>\n\n<iframe src=\"float_dash.html\" width=\"200px\" height=\"200px\" style=\"border:none; position: fixed; bottom: 10px; left: 10px; z-index: 9999;\" scrolling=\"no\"></iframe>\n",
    "supporting": [
      "06-qta_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}