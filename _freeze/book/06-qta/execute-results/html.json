{
  "hash": "8242bd9a79ebafb43e7d5a768cb88ad4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"§6 Quantitative Text Analysis Basics 📊\"\nformat:\n  html:\n    toc: true\n    code-fold: false\n    code-link: true\n    highlight-style: github\n    include-in-header:\n      text: |\n        <script src=\"quiz.js\"></script>\n        <script src=\"content-switch.js\"></script>\nfilters: \n - collapse-callout.lua\nexecute:\n  freeze: auto\n---\n\n\n\n\nWelcome to the world of quantitative text analysis! In this chapter, we'll explore the fundamental concepts and techniques used to prepare text data for analysis. We'll use a collection of classic novels as our dataset to demonstrate these concepts.\n\n::: {.callout-note}\n## Learning Objectives\n- 📖 Understand the basics of text analysis and its applications in Digital Humanities\n- 🧹 Learn essential text preprocessing techniques\n- 🔤 Explore basic text analysis concepts like tokenization and word frequency\n- 📊 Visualize text data using simple techniques like word clouds\n:::\n\n# What is Quantitative Text Analysis? 🤔\n\nQuantitative text analysis (QTA) is a method of analyzing large volumes of text data using computational techniques. It allows researchers to extract meaningful patterns, themes, and insights from textual data that would be difficult or impossible to analyze manually.\n\n## QTA in Digital Humanities\n\nIn Digital Humanities, QTA offers powerful tools for exploring large text corpora:\n\n1. **Scale**: Analyze vast collections of texts, revealing patterns across time periods, genres, or authors.\n\n2. **Distant Reading**: Observe broader patterns in literature and cultural production.\n\n3. **Hypothesis Testing**: Empirically test literary and cultural theories across large datasets.\n\n4. **Discovery**: Reveal unexpected patterns or connections, sparking new research questions.\n\n5. **Interdisciplinary**: Combine methods from linguistics, computer science, and statistics with humanistic inquiry.\n\n6. **Visualization**: Present textual data in new, visually interpretable ways.\n\nQTA complements traditional close reading, offering Digital Humanities scholars new perspectives on cultural, historical, and literary phenomena.\n\n\n# Our Dataset: Pride and Prejudice 📚\n\nFor this chapter, we'll use Jane Austen's \"Pride and Prejudice\" to demonstrate text analysis techniques. We'll access this novel using the `janeaustenr` package.\n\n## Install Package Manager `pacman`\n\nBefore we begin our text analysis, let's introduce a helpful tool for managing R packages: `pacman`. The `pacman` package is a convenient package management tool for R that simplifies the process of loading and installing multiple packages.\n\nKey features of `pacman`:\n\n1. It combines the functionality of `install.packages()` and `library()` into a single function `p_load()`.\n2. It automatically installs packages if they're not already installed.\n3. It can load multiple packages with a single line of code.\n\nLet's install and load `pacman`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(\"pacman\")) install.packages(\"pacman\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: pacman\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(pacman)\n```\n:::\n\n\n\n\nNow we can use `p_load()` to efficiently load (and install if necessary) the packages we'll need for our text analysis:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_load(janeaustenr, tidyverse)\n```\n:::\n\n\n\n\nThis single line will ensure all the packages we need are installed and loaded, streamlining our setup process.\n\nFor this chapter, we'll use Jane Austen's \"Pride and Prejudice\" to demonstrate text analysis techniques. To download the book dataset, run the following command:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_and_prejudice <- austen_books() %>%\n  filter(book == \"Pride & Prejudice\")\n\npride_and_prejudice\n```\n:::\n\n\n\n\nAlternatively, you can also download it directly here:\n\n[Download Pride and Prejudice dataset](data/pride_and_prejudice.csv)\n\nYou can create a folder named \"data\" in save the csv file in your working directorya and load the data with the following command:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npride_and_prejudice <- read_csv(\"data/pride_and_prejudice.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 13030 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): text, book\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\npride_and_prejudice\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13,030 × 2\n   text                                                                    book \n   <chr>                                                                   <chr>\n 1 PRIDE AND PREJUDICE                                                     Prid…\n 2 <NA>                                                                    Prid…\n 3 By Jane Austen                                                          Prid…\n 4 <NA>                                                                    Prid…\n 5 <NA>                                                                    Prid…\n 6 <NA>                                                                    Prid…\n 7 Chapter 1                                                               Prid…\n 8 <NA>                                                                    Prid…\n 9 <NA>                                                                    Prid…\n10 It is a truth universally acknowledged, that a single man in possession Prid…\n# ℹ 13,020 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThis gives us the full text of \"Pride and Prejudice\" in a tidy format, with one line per row.\n\n# Text Preprocessing Techniques 🧹\n\nBefore we dive into the technical aspects of preparing text for analysis, let's take a moment to think about how we interact with text in our everyday lives.\n\n::: {.callout-tip}\n## Reflection\n\nImagine you're reading a book and taking notes for a literature class. You might underline important passages, write summaries in the margins, or create a list of key themes.\n\n- What kinds of information do you focus on?\n- What do you tend to ignore or skim over?\n- How might your note-taking process change if you want to read hundreds of books instead of just one?\n\nTake a few minutes to jot down your thoughts or discuss with a classmate. These reflections can help us understand the choices we make when preparing texts for computational analysis.\n:::\n\n<div id=\"reflection-insights\" style=\"display: none;\">\n::: {.callout-note}\n## Reflection Insights\n\nWhen we read and take notes, we often:\n\n1. Focus on: main ideas, character development, plot points, themes, and notable quotes.\n2. Skim over: common words, detailed descriptions, or repetitive information.\n3. For analyzing many books: we might create more structured notes, use consistent categories across books, and focus on comparing and contrasting elements.\n\nThese human reading strategies have parallels in computational text analysis:\n\n- Focusing on key information → Extracting features or topics\n- Skimming common words → Removing stopwords\n- Structured note-taking → Creating consistent data formats\n\nAs we explore text preprocessing techniques, we'll see how these human reading strategies are adapted for computational analysis.\n:::\n</div>\n\n<script>\ncreateToggleSection('reflection-insights-button', 'reflection-insights', 'Show Insights');\n</script>\n\nNow, let's explore how computers \"read\" and prepare texts for analysis. This process, known as text preprocessing, is a crucial first step in quantitative text analysis.\n\n::: {.callout-note}\n## Understanding Text Preprocessing\n\nText preprocessing is the crucial first step in quantitative text analysis. It involves cleaning and standardizing raw text data to make it suitable for computational analysis.\n\n**Why is it important?**\n- Improves data quality and consistency\n- Reduces noise and irrelevant information\n- Enhances the accuracy of subsequent analyses\n- Makes text data more manageable for computational processing\n\n**Fundamental considerations:**\n1. **Purpose**: The preprocessing steps you choose should align with your research questions and analysis goals.\n2. **Language**: Different languages may require specific preprocessing techniques.\n3. **Domain**: The nature of your texts (e.g., literary, social media, historical) may influence preprocessing decisions.\n4. **Information preservation**: Be cautious not to remove potentially important information during preprocessing.\n5. **Reproducibility**: Document your preprocessing steps to ensure your analysis can be replicated.\n\nRemember, there's no one-size-fits-all approach to preprocessing. The techniques you apply should be carefully considered based on your specific research context.\n:::\n\n## 1. Lowercasing\n\nLowercasing converts all text to lowercase, which helps standardize the text and ensures that words like \"The\" and \"the\" are treated as the same word.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Lowercasing\nlowercased_text <- pride_and_prejudice %>%\n  mutate(text = tolower(text))\n\n# Display a few rows to see the effect\nlowercased_text %>%\n  slice_head(n = 5) %>%\n  select(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 1\n  text               \n  <chr>              \n1 pride and prejudice\n2 <NA>               \n3 by jane austen     \n4 <NA>               \n5 <NA>               \n```\n\n\n:::\n:::\n\n\n\n\n## 2. Removing Punctuation\n\nRemoving punctuation can help in word-based analyses by separating words that might be connected by punctuation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing punctuation\nno_punctuation <- pride_and_prejudice %>%\n  mutate(text = str_replace_all(text, \"[[:punct:]]\", \"\"))\n\n# Display a few rows to see the effect\nno_punctuation %>%\n  slice_head(n = 20) %>%\n  select(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 1\n   text                                                                   \n   <chr>                                                                  \n 1 PRIDE AND PREJUDICE                                                    \n 2 <NA>                                                                   \n 3 By Jane Austen                                                         \n 4 <NA>                                                                   \n 5 <NA>                                                                   \n 6 <NA>                                                                   \n 7 Chapter 1                                                              \n 8 <NA>                                                                   \n 9 <NA>                                                                   \n10 It is a truth universally acknowledged that a single man in possession \n11 of a good fortune must be in want of a wife                            \n12 <NA>                                                                   \n13 However little known the feelings or views of such a man may be on his \n14 first entering a neighbourhood this truth is so well fixed in the minds\n15 of the surrounding families that he is considered the rightful property\n16 of some one or other of their daughters                                \n17 <NA>                                                                   \n18 My dear Mr Bennet said his lady to him one day have you heard that     \n19 Netherfield Park is let at last                                        \n20 <NA>                                                                   \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip}\n## `str_replace_all` and regex\n\n`str_replace_all()` is a function from the `stringr` package (part of the tidyverse) that replaces all occurrences of a pattern in a string with another string. Common functions that are useful for working with text are:\n\n- Detecting text: `str_detect()`, `str_count()`\n- Extracting text: `str_extract()`, `str_extract_all()`\n- Replacing text: `str_replace()`, `str_replace_all()`\n- Removing text: `str_remove()`, `str_remove_all()`\n\nRegex (regular expressions) are powerful tools for pattern matching in strings. Here's a breakdown of the regex used in our example:\n\n1. `\"[[:punct:]]\"`: This pattern matches any punctuation character.\n   - `[]` defines a character set\n   - `[:punct:]` is a POSIX character class representing all punctuation\n\n2. `\"\\\\d+\"`: This pattern matches one or more digits.\n   - `\\\\d` represents any digit (equivalent to `[0-9]`)\n   - `+` means \"one or more\" of the preceding element\n\n3. `\"[^[:alnum:][:space:]]\"`: This pattern matches any character that is not alphanumeric or whitespace.\n   - `^` inside `[]` means \"not\"\n   - `[:alnum:]` matches any alphanumeric character\n   - `[:space:]` matches any whitespace character\n\nUsing these patterns with `str_replace_all()`, we can effectively clean our text by removing punctuation, numbers, and special characters.\n\nExample:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_replace_all(\"Hello, world! 123\", \"[[:punct:]]\", \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello world 123\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_replace_all(\"Hello, world! 123\", \"\\\\d+\", \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello, world! \"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_replace_all(\"Hello, world! 123 @#$\", \"[^[:alnum:][:space:]]\", \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello world 123 \"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Example of str_trim()\nstr_trim(\"  Hello, world!  \")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello, world!\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Example of str_squish()\nstr_squish(\"Hello,   world!  How   are  you?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello, world! How are you?\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Combining str_trim() and str_squish()\nstr_squish(str_trim(\"  Hello,   world!  How   are  you?  \"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello, world! How are you?\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Example of removing special characters\nstr_replace_all(\"Hello, world! 123 @#$ ñ € ß\", \"[^[:alnum:][:space:]]\", \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello world 123  ñ  ß\"\n```\n\n\n:::\n:::\n\n\n\n\n\nYou can check out [this blogpost](https://jfjelstul.github.io/regular-expressions-tutorial/) for a good variety of examples of how to use regular expressions to prepare text for analysis. Remember, the choice of regex patterns depends on your specific text cleaning needs.\n:::\n\n\nThese preprocessing steps can be combined for a more comprehensive text cleaning:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combining all preprocessing steps\nfully_preprocessed <- pride_and_prejudice %>%\n  mutate(\n    text = tolower(text),\n    text = str_replace_all(text, \"[[:punct:]]\", \"\"),\n    text = str_replace_all(text, \"\\\\d+\", \"\"),\n    text = str_trim(text),\n    text = str_squish(text),\n    text = str_replace_all(text, \"[^[:alnum:][:space:]]\", \"\")\n  )\n\n# Display a few rows to see the combined effect\nfully_preprocessed %>%\n  slice_head(n = 20) %>%\n  select(text)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 1\n   text                                                                   \n   <chr>                                                                  \n 1 pride and prejudice                                                    \n 2 <NA>                                                                   \n 3 by jane austen                                                         \n 4 <NA>                                                                   \n 5 <NA>                                                                   \n 6 <NA>                                                                   \n 7 chapter                                                                \n 8 <NA>                                                                   \n 9 <NA>                                                                   \n10 it is a truth universally acknowledged that a single man in possession \n11 of a good fortune must be in want of a wife                            \n12 <NA>                                                                   \n13 however little known the feelings or views of such a man may be on his \n14 first entering a neighbourhood this truth is so well fixed in the minds\n15 of the surrounding families that he is considered the rightful property\n16 of some one or other of their daughters                                \n17 <NA>                                                                   \n18 my dear mr bennet said his lady to him one day have you heard that     \n19 netherfield park is let at last                                        \n20 <NA>                                                                   \n```\n\n\n:::\n:::\n\n\n\n\nEach of these preprocessing steps serves a specific purpose in preparing the text for analysis. The choice of which steps to apply depends on the specific goals of your analysis and the nature of your text data. \n\n::: {.callout-tip}\n## Understanding the Implications of Preprocessing\n\nIt's crucial to carefully consider and document each preprocessing step you apply to your text data. These decisions can significantly impact your analysis results:\n\n1. **Information Loss**: Some preprocessing steps (like removing punctuation or lowercasing) can remove potentially important information.\n2. **Analysis Bias**: Certain preprocessing choices might inadvertently introduce bias into your analysis.\n3. **Interpretability**: Your preprocessing decisions affect how you can interpret your results later.\n4. **Reproducibility**: Documenting your preprocessing steps is essential for others to reproduce or build upon your work.\n5. **Domain Specificity**: The appropriate preprocessing steps can vary depending on your field of study and the specific texts you're analyzing.\n\n*Always think critically about why you're applying each preprocessing step and how it might affect your analysis outcomes*. When in doubt, it's often helpful to try multiple preprocessing approaches and compare the results. \n:::\n\n## Learning Check 🏁 \n\n<div id=\"quiz-qta\"></div>\n\n<script>\ncreateQuiz({\n  questions: [\n    {\n      text: \"What is the primary purpose of text preprocessing in quantitative text analysis?\",\n      options: [\n        \"To make the text more readable for humans\",\n        \"To prepare the text for computational analysis\",\n        \"To translate the text into different languages\",\n        \"To increase the text's word count\"\n      ]\n    },\n    {\n      text: \"What does the `tolower()` function do in R?\",\n      options: [\n        \"Removes all lowercase letters\",\n        \"Converts text to uppercase\",\n        \"Converts text to lowercase\",\n        \"Removes all uppercase letters\"\n      ]\n    },\n    {\n      text: \"In the context of regex, what does the pattern `[[:punct:]]` match?\",\n      options: [\n        \"All alphabetic characters\",\n        \"All numeric characters\",\n        \"All punctuation characters\",\n        \"All whitespace characters\"\n      ]\n    },\n    {\n      text: \"What is the purpose of the `str_replace_all()` function in text preprocessing?\",\n      options: [\n        \"To count the occurrences of a pattern\",\n        \"To extract specific patterns from text\",\n        \"To replace all occurrences of a pattern with another string\",\n        \"To split text into individual words\"\n      ]\n    }\n  ],\n  answers: [1, 2, 2, 2]\n}, \"quiz-qta\");\n</script>\n\n\n\n<iframe src=\"float_traffic.html\" width=\"200px\" height=\"200px\" style=\"border:none; position: fixed; bottom: 10px; right: 10px; z-index: 9999;\" scrolling=\"no\"></iframe>\n\n<iframe src=\"float_dash.html\" width=\"200px\" height=\"200px\" style=\"border:none; position: fixed; bottom: 10px; left: 10px; z-index: 9999;\" scrolling=\"no\"></iframe>\n",
    "supporting": [
      "06-qta_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}