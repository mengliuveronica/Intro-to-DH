---
title: "§6 Quantitative Text Analysis Basics 📊"
format:
  html:
    toc: true
    code-fold: false
    code-link: true
    highlight-style: github
    include-in-header:
      text: |
        <script src="quiz.js"></script>
        <script src="content-switch.js"></script>
filters: 
 - collapse-callout.lua
execute:
  freeze: auto
---

Welcome to the world of quantitative text analysis! In this chapter, we'll explore the fundamental concepts and techniques used to prepare text data for analysis. We'll use a collection of classic novels as our dataset to demonstrate these concepts.

::: {.callout-note}
## Learning Objectives
- 📖 Understand the basics of text analysis and its applications in Digital Humanities
- 🧹 Learn essential text preprocessing techniques
- 🔤 Explore basic text analysis concepts like tokenization and word frequency
- 📊 Visualize text data using simple techniques like word clouds
:::

# What is Quantitative Text Analysis? 🤔

Quantitative text analysis (QTA) is a method of analyzing large volumes of text data using computational techniques. It allows researchers to extract meaningful patterns, themes, and insights from textual data that would be difficult or impossible to analyze manually.

## QTA in Digital Humanities

In Digital Humanities, QTA offers powerful tools for exploring large text corpora:

1. **Scale**: Analyze vast collections of texts, revealing patterns across time periods, genres, or authors.

2. **Distant Reading**: Observe broader patterns in literature and cultural production.

3. **Hypothesis Testing**: Empirically test literary and cultural theories across large datasets.

4. **Discovery**: Reveal unexpected patterns or connections, sparking new research questions.

5. **Interdisciplinary**: Combine methods from linguistics, computer science, and statistics with humanistic inquiry.

6. **Visualization**: Present textual data in new, visually interpretable ways.

QTA complements traditional close reading, offering Digital Humanities scholars new perspectives on cultural, historical, and literary phenomena.


# Our Dataset: Pride and Prejudice 📚

For this chapter, we'll use Jane Austen's "Pride and Prejudice" to demonstrate text analysis techniques. We'll access this novel using the `janeaustenr` package.

## Install Package Manager `pacman`

Before we begin our text analysis, let's introduce a helpful tool for managing R packages: `pacman`. The `pacman` package is a convenient package management tool for R that simplifies the process of loading and installing multiple packages.

Key features of `pacman`:

1. It combines the functionality of `install.packages()` and `library()` into a single function `p_load()`.
2. It automatically installs packages if they're not already installed.
3. It can load multiple packages with a single line of code.

Let's install and load `pacman`:

```{r}
if (!require("pacman")) install.packages("pacman")
library(pacman)
```

Now we can use `p_load()` to efficiently load (and install if necessary) the packages we'll need for our text analysis:

```{r}
p_load(janeaustenr, tidyverse)
```

This single line will ensure all the packages we need are installed and loaded, streamlining our setup process.

For this chapter, we'll use Jane Austen's "Pride and Prejudice" to demonstrate text analysis techniques. To download the book dataset, run the following command:

```{r eval=FALSE}

pride_and_prejudice <- austen_books() %>%
  filter(book == "Pride & Prejudice")

pride_and_prejudice
```

Alternatively, you can also download it directly here:

[Download Pride and Prejudice dataset](data/pride_and_prejudice.csv)

You can create a folder named "data" in save the csv file in your working directorya and load the data with the following command:

```{r}
pride_and_prejudice <- read_csv("data/pride_and_prejudice.csv")

pride_and_prejudice
```

This gives us the full text of "Pride and Prejudice" in a tidy format, with one line per row.

# Text Preprocessing Techniques 🧹

Before we dive into the technical aspects of preparing text for analysis, let's take a moment to think about how we interact with text in our everyday lives.

::: {.callout-tip}
## Reflection

Imagine you're reading a book and taking notes for a literature class. You might underline important passages, write summaries in the margins, or create a list of key themes.

- What kinds of information do you focus on?
- What do you tend to ignore or skim over?
- How might your note-taking process change if you want to read hundreds of books instead of just one?

Take a few minutes to jot down your thoughts or discuss with a classmate. These reflections can help us understand the choices we make when preparing texts for computational analysis.
:::

<div id="reflection-insights" style="display: none;">
::: {.callout-note}
## Reflection Insights

When we read and take notes, we often:

1. Focus on: main ideas, character development, plot points, themes, and notable quotes.
2. Skim over: common words, detailed descriptions, or repetitive information.
3. For analyzing many books: we might create more structured notes, use consistent categories across books, and focus on comparing and contrasting elements.

These human reading strategies have parallels in computational text analysis:

- Focusing on key information → Extracting features or topics
- Skimming common words → Removing stopwords
- Structured note-taking → Creating consistent data formats

As we explore text preprocessing techniques, we'll see how these human reading strategies are adapted for computational analysis.
:::
</div>

<script>
createToggleSection('reflection-insights-button', 'reflection-insights', 'Show Insights');
</script>

Now, let's explore how computers "read" and prepare texts for analysis. This process, known as text preprocessing, is a crucial first step in quantitative text analysis.

::: {.callout-note}
## Understanding Text Preprocessing

Text preprocessing is the crucial first step in quantitative text analysis. It involves cleaning and standardizing raw text data to make it suitable for computational analysis.

**Why is it important?**

- Improves data quality and consistency
- Reduces noise and irrelevant information
- Enhances the accuracy of subsequent analyses
- Makes text data more manageable for computational processing

**Fundamental considerations:**

1. **Purpose**: The preprocessing steps you choose should align with your research questions and analysis goals.
2. **Language**: Different languages may require specific preprocessing techniques.
3. **Domain**: The nature of your texts (e.g., literary, social media, historical) may influence preprocessing decisions.
4. **Information preservation**: Be cautious not to remove potentially important information during preprocessing.
5. **Reproducibility**: Document your preprocessing steps to ensure your analysis can be replicated.

Remember, there's no one-size-fits-all approach to preprocessing. The techniques you apply should be carefully considered based on your specific research context.
:::

## 1. Lowercasing

Lowercasing converts all text to lowercase, which helps standardize the text and ensures that words like "The" and "the" are treated as the same word.

```{r}
# Lowercasing
lowercased_text <- pride_and_prejudice %>%
  mutate(text = tolower(text))

# Display a few rows to see the effect
lowercased_text %>%
  slice_head(n = 5) %>%
  select(text)
```

## 2. Removing Punctuation

Removing punctuation can help in word-based analyses by separating words that might be connected by punctuation.

```{r}
# Removing punctuation
no_punctuation <- pride_and_prejudice %>%
  mutate(text = str_replace_all(text, "[[:punct:]]", ""))

# Display a few rows to see the effect
no_punctuation %>%
  slice_head(n = 20) %>%
  select(text)
```

:::{.callout-tip}
## `str_replace_all` and regex

`str_replace_all()` is a function from the `stringr` package (part of the tidyverse) that replaces all occurrences of a pattern in a string with another string. Common functions that are useful for working with text are:

- Detecting text: `str_detect()`, `str_count()`
- Extracting text: `str_extract()`, `str_extract_all()`
- Replacing text: `str_replace()`, `str_replace_all()`
- Removing text: `str_remove()`, `str_remove_all()`

Regex (regular expressions) are powerful tools for pattern matching in strings. Here's a breakdown of the regex used in our example:

1. `"[[:punct:]]"`: This pattern matches any punctuation character.
   - `[]` defines a character set
   - `[:punct:]` is a POSIX character class representing all punctuation

2. `"\\d+"`: This pattern matches one or more digits.
   - `\\d` represents any digit (equivalent to `[0-9]`)
   - `+` means "one or more" of the preceding element

3. `"[^[:alnum:][:space:]]"`: This pattern matches any character that is not alphanumeric or whitespace.
   - `^` inside `[]` means "not"
   - `[:alnum:]` matches any alphanumeric character
   - `[:space:]` matches any whitespace character

Using these patterns with `str_replace_all()`, we can effectively clean our text by removing punctuation, numbers, and special characters.

Example:
```{r}
str_replace_all("Hello, world! 123", "[[:punct:]]", "")
 

str_replace_all("Hello, world! 123", "\\d+", "")
 

str_replace_all("Hello, world! 123 @#$", "[^[:alnum:][:space:]]", "")
 

# Example of str_trim()
str_trim("  Hello, world!  ")
 

# Example of str_squish()
str_squish("Hello,   world!  How   are  you?")
 

# Combining str_trim() and str_squish()
str_squish(str_trim("  Hello,   world!  How   are  you?  "))
 

# Example of removing special characters
str_replace_all("Hello, world! 123 @#$ ñ € ß", "[^[:alnum:][:space:]]", "")
 
```


You can check out [this blogpost](https://jfjelstul.github.io/regular-expressions-tutorial/) for a good variety of examples of how to use regular expressions to prepare text for analysis. Remember, the choice of regex patterns depends on your specific text cleaning needs.
:::


These preprocessing steps can be combined for a more comprehensive text cleaning:

```{r}
# Combining all preprocessing steps
fully_preprocessed <- pride_and_prejudice %>%
  mutate(
    text = tolower(text),
    text = str_replace_all(text, "[[:punct:]]", ""),
    text = str_replace_all(text, "\\d+", ""),
    text = str_trim(text),
    text = str_squish(text),
    text = str_replace_all(text, "[^[:alnum:][:space:]]", "")
  )

# Display a few rows to see the combined effect
fully_preprocessed %>%
  slice_head(n = 20) %>%
  select(text)
```

Each of these preprocessing steps serves a specific purpose in preparing the text for analysis. The choice of which steps to apply depends on the specific goals of your analysis and the nature of your text data. 

::: {.callout-tip}
## Understanding the Implications of Preprocessing

It's crucial to carefully consider and document each preprocessing step you apply to your text data. These decisions can significantly impact your analysis results:

1. **Information Loss**: Some preprocessing steps (like removing punctuation or lowercasing) can remove potentially important information.
2. **Analysis Bias**: Certain preprocessing choices might inadvertently introduce bias into your analysis.
3. **Interpretability**: Your preprocessing decisions affect how you can interpret your results later.
4. **Reproducibility**: Documenting your preprocessing steps is essential for others to reproduce or build upon your work.
5. **Domain Specificity**: The appropriate preprocessing steps can vary depending on your field of study and the specific texts you're analyzing.

*Always think critically about why you're applying each preprocessing step and how it might affect your analysis outcomes*. When in doubt, it's often helpful to try multiple preprocessing approaches and compare the results. 
:::

## Learning Check 🏁 

<div id="quiz-qta"></div>

<script>
createQuiz({
  questions: [
    {
      text: "What is the primary purpose of text preprocessing in quantitative text analysis?",
      options: [
        "To make the text more readable for humans",
        "To prepare the text for computational analysis",
        "To translate the text into different languages",
        "To increase the text's word count"
      ]
    },
    {
      text: "What does the `tolower()` function do in R?",
      options: [
        "Removes all lowercase letters",
        "Converts text to uppercase",
        "Converts text to lowercase",
        "Removes all uppercase letters"
      ]
    },
    {
      text: "In the context of regex, what does the pattern `[[:punct:]]` match?",
      options: [
        "All alphabetic characters",
        "All numeric characters",
        "All punctuation characters",
        "All whitespace characters"
      ]
    },
    {
      text: "What is the purpose of the `str_replace_all()` function in text preprocessing?",
      options: [
        "To count the occurrences of a pattern",
        "To extract specific patterns from text",
        "To replace all occurrences of a pattern with another string",
        "To split text into individual words"
      ]
    }
  ],
  answers: [1, 2, 2, 2]
}, "quiz-qta");
</script>



<iframe src="float_traffic.html" width="200px" height="200px" style="border:none; position: fixed; bottom: 10px; right: 10px; z-index: 9999;" scrolling="no"></iframe>

<iframe src="float_dash.html" width="200px" height="200px" style="border:none; position: fixed; bottom: 10px; left: 10px; z-index: 9999;" scrolling="no"></iframe>
